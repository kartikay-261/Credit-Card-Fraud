{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a06a69-9539-46f7-bb3c-23050703813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40508d4f-bd48-4966-97ce-5ad0eeef3021",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6ab2fa-6dc5-4522-82f8-6f091e2b386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6362620 entries, 0 to 6362619\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   step            int64  \n",
      " 1   type            object \n",
      " 2   amount          float64\n",
      " 3   nameOrig        object \n",
      " 4   oldbalanceOrg   float64\n",
      " 5   newbalanceOrig  float64\n",
      " 6   nameDest        object \n",
      " 7   oldbalanceDest  float64\n",
      " 8   newbalanceDest  float64\n",
      " 9   isFraud         int64  \n",
      " 10  isFlaggedFraud  int64  \n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 534.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#Reading the dataset and peeking into the structure of the data\n",
    "fraud=pd.read_csv(\"D:\\download\\Fraud.csv\")\n",
    "fraud.shape\n",
    "fraud.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9d1be-c66d-4b50-9974-3489922ae239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting head of the dataset\n",
    "fraud.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0427a8e-fd95-40f3-99c0-727d82521314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if any null values are present \n",
    "#null values can be replaced with mean for the row\n",
    "fraud.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1224e178-4d44-4ac8-8927-45b543737d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Leg=len(fraud[fraud.isFraud==0])\n",
    "frud=len(fraud[fraud.isFraud==1])\n",
    "Leg_per=(Leg/(Leg+frud))*100\n",
    "Fra_per=(frud/(Leg+frud))*100\n",
    "print(\"Number of Legit transactions: \", Leg)\n",
    "print(\"Number of Fraud transactions: \", frud)\n",
    "print(\"Percentage of Legit transactions: {:.4f} %\".format(Leg_per))\n",
    "print(\"Percentage of Fraud transactions: {:.4f} %\".format(Fra_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db51e6e-5250-4a02-b269-a3a827604f16",
   "metadata": {},
   "source": [
    "These results demonstrate that the dataset is higly unbalanced with only 0.129% of the transactions being fraudulent therefore we can use decision tree or a metamodel of decision trees to average out the bias towards any class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc932f-c9f3-4821-9d26-bbe1abe0d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=fraud.drop(['type','nameOrig','nameDest'],axis=1)\n",
    "corr=cr.corr()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731e743-f387-41f6-bc4a-81b1c75eaebf",
   "metadata": {},
   "source": [
    "Based on the co-relation Heatmap we drop can drop the columns that bear low co-relation to the attribute that we have to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f629a811-8a8a-48a1-b78b-8d083b3c1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,10))\n",
    "labels = [\"Legit\", \"Fraud\"]\n",
    "count_classes = fraud.value_counts(fraud['isFraud'], sort= True)\n",
    "count_classes.plot(kind = \"bar\", rot = 0)\n",
    "plt.title(\"Visualization of Labels\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(range(2), labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c402d2-9059-45b7-a270-c1b632b8bc3b",
   "metadata": {},
   "source": [
    "Data manupilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36fa9ab-3163-46e4-8915-8fb0618f2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy to keep the original dataset safe\n",
    "df= fraud.copy()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attributes that are objects need to be label encoded therefore we check for them\n",
    "objList = df.select_dtypes(include = \"object\").columns\n",
    "print (objList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Lab= LabelEncoder()\n",
    "\n",
    "for fea in objList:\n",
    "    df[fea]=Lab.fit_transform(df[fea].astype(str))\n",
    "    \n",
    "print (df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085bb33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking the VIF(variation inflation factor) score to check for collinearity and we will omit the highly correlated attributes\n",
    "def calc_vif(df):\n",
    "\n",
    "    \n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = df.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "\n",
    "    return(vif)\n",
    "\n",
    "calc_vif(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "214029da-d035-4661-9bb3-70ce3db14aa4",
   "metadata": {},
   "source": [
    "[oldbalanceOrg, newbalanceOrig, oldbalanceDest,newbalanceDest] have a high VIF therefor we can combine these colums. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334287ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['Actual_amount_orig'] = df.apply(lambda x: x['oldbalanceOrg'] - x['newbalanceOrig'],axis=1)\n",
    "df['Actual_amount_dest'] = df.apply(lambda x: x['oldbalanceDest'] - x['newbalanceDest'],axis=1)\n",
    "df['TransactionPath'] = df.apply(lambda x: x['nameOrig'] + x['nameDest'],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebeb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest','step','nameOrig','nameDest'],axis=1)\n",
    "\n",
    "calc_vif(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5580df",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=df.corr()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(corr,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44031e1-3233-48ea-9629-a6c2b282853e",
   "metadata": {},
   "source": [
    "                                                              1.1\n",
    "MODEL generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef4e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling \n",
    "scaler = StandardScaler()\n",
    "df[\"NormalizedAmount\"] = scaler.fit_transform(df[\"amount\"].values.reshape(-1, 1))\n",
    "df.drop([\"amount\"], inplace= True, axis= 1)\n",
    "\n",
    "Y = df[\"isFraud\"]\n",
    "X = df.drop([\"isFraud\"], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f6b26-45a1-485f-9b34-a1ff1a7a9cd7",
   "metadata": {},
   "source": [
    "scaling the entire dataset could decrease the accuracy however the transaction amount has a very high range therefore we should scale this down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size= 0.3, random_state= 42)\n",
    "\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training decision tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_dt = decision_tree.predict(X_test)\n",
    "decision_tree_score = decision_tree.score(X_test, Y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc2b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training random forest\n",
    "random_forest = RandomForestClassifier(n_estimators= 100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_rf = random_forest.predict(X_test)\n",
    "random_forest_score = random_forest.score(X_test, Y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33830096",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ece1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores\n",
    "print(\"Decision Tree Score: \", decision_tree_score)\n",
    "print(\"Random Forest Score: \", random_forest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e0058-140e-4c8c-90dc-42d247145e28",
   "metadata": {},
   "source": [
    "Both the models show a good score however random forest shows a better score compared to decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12715800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix terms-Decision Trees\n",
    "\n",
    "\n",
    "print(\"TP,FP,TN,FN - Decision Tree\")\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred_dt).ravel()\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Negatives: {fn}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3047d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix terms-Random Forest \n",
    "print(\"TP,FP,TN,FN - Random Forest\")\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred_rf).ravel()\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Negatives: {fn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aa8a63-fbc7-4884-8178-6abeab2fdeda",
   "metadata": {},
   "source": [
    "TP(Decision Tree) ~ TP(Random Forest)- Both models are nearly equal for this\n",
    "FP(Decision Tree) > FP(Random Forest) - Random Forest is better\n",
    "TN(Decision Tree) < TN(Random Forest) - Random Forest is better here also\n",
    "FN(Decision Tree) ~ FN(Random Forest)\n",
    "\n",
    "\n",
    "Therefore Random forest performs better here also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix -DT\n",
    "confusion_matrix_dt = confusion_matrix(Y_test, Y_pred_dt.round())\n",
    "print(\"Confusion Matrix - Decision Tree\")\n",
    "print(confusion_matrix_dt,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix-RF\n",
    "confusion_matrix_rf = confusion_matrix(Y_test, Y_pred_rf.round())\n",
    "print(\"Confusion Matrix - Random Forest\")\n",
    "print(confusion_matrix_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987abe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report-DT\n",
    "classification_report_dt = classification_report(Y_test, Y_pred_dt)\n",
    "print(\"Classification Report - Decision Tree\")\n",
    "print(classification_report_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report-RF\n",
    "classification_report_rf = classification_report(Y_test, Y_pred_rf)\n",
    "print(\"Classification Report - Random Forest\")\n",
    "print(classification_report_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea54b3-bfeb-4467-8910-c8bf9955200b",
   "metadata": {},
   "source": [
    "The good precision and F1 score random forest is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise the CM\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_dt)\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix - DT')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_rf)\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix - RF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea6f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AOC-ROC-DT\n",
    "\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(Y_test, Y_pred_dt)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('ROC - DT')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AOC-ROC-RF\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(Y_test, Y_pred_rf)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('ROC - RF')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af17fa-5a47-4d46-bec8-adff5a8af865",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\\\\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-The  tehhe- T__-- -\n",
    "-The Data had no null values we checked fir or that \n",
    "Most o. The algorithms we isuused decision treaea ss and rafor our prediction ndom forest are inherently insesnsitive toward outliers. We used both a correlation matrix and the VIF criteria to check for multicollinera-arity and removed the featurcombined these features to create a new feature more useful forour analysis._- The Model wehave used and would prefer to use is random forest a (I ominabination odf decision trees, wthe dataaset we have is higly unbalanced  random forest trains its cdecision trees takinfg e using a subset of the data comprising of equalnumber o f fraudulent and legittimate transactions , . Besiddes this rthey are robust and immune to  tpto noiseoutliers therefore we have used random forest I this mprejooject.- The variables we have selected to be included arethe ones which have a high correlation to the isFraud attribute . besuNBesides this t he attributes having high ccorelation to each other are dropped and repl this the attributes having high correlation with eacha tThe are replaced with a single attribute.\n",
    "\n",
    ". Demonstrate the performance of the model by using best set of tools.\n",
    "- The set of tools best demostrating the models performance would be a confusion matrix which is pasted below as we need a high precision scoresas to not let a single fraudulent transaction happen even if a few legitimate transactions are stopped.\n",
    "  Classification Report - Random Forest\r\n",
    "              precision    recall  f1-score   support\r\n",
    "\r\n",
    "           0       1.00      1.00      1.00   1906351\r\n",
    "           1       0.96      0.70      0.81      2435\r\n",
    "\r\n",
    "    accuracy                           1.00   1908786\r\n",
    "   macro avg       0.98      0.85      0.91   1908786\r\n",
    "weighted avg       1.00      1.00      1.00  - the The key factors for predicting fraudulent transactions in \\based on the heatmap are 'Actual-_origin_amount' and other 'Amount' of transaction .O Other factors that would bmake sense but are nit ot included in the dataset arewould be secured request rportal, Aa Transsaaction history of requestor.- These factors make sense as the target of fraudulent transactions would be typically amouccounts woth ith a similar balcance , Iif the person id s nearly vabankrupt or a multi-millionair e most probably they would not be in the targteet list of the fraudsters. The amount makes sense as the is self explantory as an amount to o high would beeasil fall y fall into notivce and a very small amount would bnot be worth the effort fora fraud.\n",
    "-Th Based on this data the ccompany should introduce a real time fraud detection system in their pipeline which flagsa any such transactions ansd delays them unti further haltsconfirmation .  Other than this the company could enswarn the user anytime a payment is being made to a vendor that is not secure or has a sketchy apayment history . A pipelin e could be made gild be made f A number of flags could be used base od on previous reported cases from any s and include an option to report such transactions(subsequently flagging the vendor) uch combination of theseunt and otherto secure the transactions.\n",
    "- The best method to check if they work or not would be to intriooduce thseese methods into a subset of the pipleline unaccessible to the pubklic and run a numbberer of cthese transactions ofn the system m and check if the new pipeline is abele to single out the fraudulent transactions . This would ensure that further finetuning and checks can be made in thhee systmodel before relasing easing tit to the ouupublic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
